{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"dataset.ipynb","provenance":[],"authorship_tag":"ABX9TyOz7xxMYnLL2jWxJzEYM7ul"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6-final"}},"cells":[{"source":["# Script para generar un dataset (pelota de plata)\n","\n","Se pretende generar un dataset compatible con la librería datasets para utilizarlo en transformers. Este script es único para pelota de plata.\n","\n","Primero importamos las librerías."],"cell_type":"markdown","metadata":{}},{"cell_type":"code","metadata":{"id":"f2_pK489dWM_"},"source":["import datasets\n","import json"],"execution_count":1,"outputs":[]},{"source":["#### Establecemos la metadata del dataset"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","metadata":{"id":"C9gBuUuWe7-r"},"source":["_DESCRIPTION = 'CSV secundaria para NLP'\n","_ULR = 'https://github.com/ValverDEV/NLPCogEval/blob/main/datasets/JSON/pelota_plata.json?raw=true'\n","_CITATION = ''\n","\n","logger = datasets.logging.get_logger(__name__)"],"execution_count":3,"outputs":[]},{"source":["## Clases que permitirán al script ser cargado desde otro archivo usando _datasets.load_dataset()_"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","metadata":{"id":"l3LPZSqzdVCw"},"source":["class NLPConfig(datasets.BuilderConfig):\n","\n","  def __init__(self, **kwargs):\n","\n","    super(NLPConfig, self).__init__(**kwargs)\n","\n","\n","class NLP(datasets.GeneratorBasedBuilder):\n","\n","  BuilderConfig = [\n","    NLPConfig(\n","      name='plain_text',\n","      version=datasets.Version('1.0.0',''),\n","      description='Plain text',\n","    ),\n","  ]\n","\n","  def _info(self):\n","    return datasets.DatasetInfo(\n","        description = _DESCRIPTION,\n","        features = datasets.Features(\n","            {\n","                'answer' : datasets.Value('string'),\n","                'label' : datasets.Value('bool')\n","            }\n","        ),\n","    citation=_CITATION\n","    )\n","\n","\n","    def _split_generators(self, dl_manager):\n","      downloaded_files = dl_manager.download_and_extract(_URL)\n","\n","      return [\n","              datasets.SplitGenerator(name=datasets.Split.TRAIN, gen_kwargs={'filepath': downloaded_files['train']}),\n","              datasets.SplitGenerator(name=datasets.Split.VALIDATION, gen_kwargs={'filepath': downloaded_files['dev']})\n","      ]\n","\n","    def _generate_examples(self, filepath):\n","      logger.info(f'generating examples from, {filepath}')\n","      with open(filepath, encoding='latin1') as f:\n","        datos = json.load(f)\n","        for respuesta in datos:\n","          answer = respuesta['answer']\n","          label = respuesta['label']\n","\n","          yield id_, {\n","              'answer' : answer,\n","              'label' : label\n","          }"],"execution_count":6,"outputs":[]}]}