{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.7 64-bit ('tf': conda)",
   "metadata": {
    "interpreter": {
     "hash": "e1a15f85f87e15897dd360be1363bc64fce3cab7a5472eb00f705ba2d772f772"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2ForSequenceClassification, TrainingArguments, Trainer\n",
    "import pandas as pd\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using custom data configuration default-964874b90c883f0d\n",
      "0 tables [00:00, ? tables/s]Downloading and preparing dataset csv/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to C:\\Users\\mv502\\.cache\\huggingface\\datasets\\csv\\default-964874b90c883f0d\\0.0.0\\2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0...\n",
      "Dataset csv downloaded and prepared to C:\\Users\\mv502\\.cache\\huggingface\\datasets\\csv\\default-964874b90c883f0d\\0.0.0\\2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('csv', data_files={\n",
    "    'train' : 'pelota_plata_train.csv',\n",
    "    'test' : 'pelota_plata_test.csv'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "datasets.dataset_dict.DatasetDict"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "type(dataset)"
   ]
  },
  {
   "source": [
    "## Leemos los datos"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = pd.read_csv('palabras_corregidas_secundaria.csv', encoding='latin1')"
   ]
  },
  {
   "source": [
    "## Ecojemos la pregunta *Pelota de Pelos*"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                              sentence  label\n",
       "0                                que es dura o aguanta      1\n",
       "1    puede ser una medalla o una esfera color metál...      1\n",
       "2                                             una joya      1\n",
       "3                         seria muy brillosa la pelota      2\n",
       "4               da a conocer que que es uno muy fuerte      3\n",
       "..                                                 ...    ...\n",
       "465        pues tal vez la medalla esta llena de plata      1\n",
       "466  yo puse que la frase se podría referir a la lu...      3\n",
       "467                                   que es brillante      3\n",
       "468  porque ya establecimos que a todo le esta dici...      1\n",
       "469  la luna se ve como de plata o color plata y br...      3\n",
       "\n",
       "[470 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentence</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>que es dura o aguanta</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>puede ser una medalla o una esfera color metál...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>una joya</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>seria muy brillosa la pelota</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>da a conocer que que es uno muy fuerte</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>465</th>\n      <td>pues tal vez la medalla esta llena de plata</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>466</th>\n      <td>yo puse que la frase se podría referir a la lu...</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>467</th>\n      <td>que es brillante</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>468</th>\n      <td>porque ya establecimos que a todo le esta dici...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>469</th>\n      <td>la luna se ve como de plata o color plata y br...</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n<p>470 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "datos = pd.DataFrame({\n",
    "    'sentence' : csv.iloc[:,4],\n",
    "    'label' : csv.iloc[:,5]\n",
    "})\n",
    "datos"
   ]
  },
  {
   "source": [
    "## Convertimos los 3 en 1 y todo lo demás en 0, para hacer una predicción binaria"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                              sentence  label\n",
       "0                                que es dura o aguanta      0\n",
       "1    puede ser una medalla o una esfera color metál...      0\n",
       "2                                             una joya      0\n",
       "3                         seria muy brillosa la pelota      0\n",
       "4               da a conocer que que es uno muy fuerte      1\n",
       "..                                                 ...    ...\n",
       "465        pues tal vez la medalla esta llena de plata      0\n",
       "466  yo puse que la frase se podría referir a la lu...      1\n",
       "467                                   que es brillante      1\n",
       "468  porque ya establecimos que a todo le esta dici...      0\n",
       "469  la luna se ve como de plata o color plata y br...      1\n",
       "\n",
       "[470 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentence</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>que es dura o aguanta</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>puede ser una medalla o una esfera color metál...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>una joya</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>seria muy brillosa la pelota</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>da a conocer que que es uno muy fuerte</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>465</th>\n      <td>pues tal vez la medalla esta llena de plata</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>466</th>\n      <td>yo puse que la frase se podría referir a la lu...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>467</th>\n      <td>que es brillante</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>468</th>\n      <td>porque ya establecimos que a todo le esta dici...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>469</th>\n      <td>la luna se ve como de plata o color plata y br...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>470 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "datos['label'] = [1 if i == 3 else 0 for i in datos['label'].tolist()]\n",
    "datos"
   ]
  },
  {
   "source": [
    "## Importamos el tokenizer y el modelo"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at datificate/gpt2-small-spanish were not used when initializing GPT2ForSequenceClassification: ['lm_head.weight']\n",
      "- This IS expected if you are initializing GPT2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing GPT2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at datificate/gpt2-small-spanish and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "num_labels = 2\n",
    "model_checkpoint = 'datificate/gpt2-small-spanish'\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_checkpoint)\n",
    "model = GPT2ForSequenceClassification.from_pretrained(model_checkpoint, num_labels=num_labels)\n"
   ]
  },
  {
   "source": [
    "#### TrainingArguments es una clase para los argumentos del entrenamiento"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\mv502\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\cuda\\__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  ..\\c10\\cuda\\CUDAFunctions.cpp:100.)\n  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "args = TrainingArguments(\n",
    "    'prueba-gpt2',\n",
    "    evaluation_strategy='epoch',\n",
    "    learning_rate = 2e-5,\n",
    "    # per_device_train_batch_size= ------------- opcional\n",
    "    # per_device_eval_batch_size = ------------ opcional\n",
    "    num_train_epochs = 5,\n",
    "    weight_decay = 0.01,\n",
    "    load_best_model_at_end = True,\n",
    "    # metric_for_best_model = \n",
    ")"
   ]
  },
  {
   "source": [
    "## Separamos las oraciones y las labels"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = datos['sentence'].tolist()\n",
    "labels = datos['label'].tolist()"
   ]
  },
  {
   "source": [
    "## Creamos un Training y Test Set"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = []\n",
    "porcentaje_entrenamiento = 0.75\n",
    "s = sentences.copy()\n",
    "l = labels.copy()\n",
    "for i in range(int(len(l)*porcentaje_entrenamiento)):\n",
    "    n = randint(0, len(l) -1)\n",
    "    training.append({'sentence': s.pop(n), 'label': l.pop(n)})\n",
    "test = [{'sentence': s[i], 'labels': l[i]} for i in range(len(s))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "352\n118\n470\n"
     ]
    }
   ],
   "source": [
    "print(len(training))\n",
    "print(len(test))\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleAttributeError",
     "evalue": "'GPT2ForSequenceClassification' object has no attribute 'model_parallel'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleAttributeError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-102-3e88441445ca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mtrain_dataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0meval_dataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mtokenizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m )\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers-4.2.2-py3.8.egg\\transformers\\trainer.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, compute_metrics, callbacks, optimizers)\u001b[0m\n\u001b[0;32m    271\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_init\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_init\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 273\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"is_parallelizable\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_parallelizable\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_parallel\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    274\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_model_parallel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    777\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m         raise ModuleAttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[1;32m--> 779\u001b[1;33m             type(self).__name__, name))\n\u001b[0m\u001b[0;32m    780\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Module'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleAttributeError\u001b[0m: 'GPT2ForSequenceClassification' object has no attribute 'model_parallel'"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=training,\n",
    "    eval_dataset=test,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}