{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.7 64-bit ('tf': conda)",
   "metadata": {
    "interpreter": {
     "hash": "e1a15f85f87e15897dd360be1363bc64fce3cab7a5472eb00f705ba2d772f772"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2ForSequenceClassification, TrainingArguments, Trainer\n",
    "import pandas as pd\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using custom data configuration default\n",
      "Downloading and preparing dataset nlp/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to C:\\Users\\mv502\\.cache\\huggingface\\datasets\\nlp\\default\\0.0.0\\6fb6208fe296414d9c120c127158cef4dc9e6f13ac16ab3ebb16989d1004c096...\n",
      "                                {'answer': 'pues la luna brilla como plata', 'label': 3}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "{'answer': 'pues la luna brilla como plata', 'label': 3}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "'id'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-e00c09400c58>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'custom_dataset.py'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\datasets\\load.py\u001b[0m in \u001b[0;36mload_dataset\u001b[1;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, ignore_verifications, keep_in_memory, save_infos, script_version, use_auth_token, **config_kwargs)\u001b[0m\n\u001b[0;32m    745\u001b[0m         \u001b[0mtry_from_hf_gcs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtry_from_hf_gcs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    746\u001b[0m         \u001b[0mbase_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbase_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 747\u001b[1;33m         \u001b[0muse_auth_token\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_auth_token\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    748\u001b[0m     )\n\u001b[0;32m    749\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\datasets\\builder.py\u001b[0m in \u001b[0;36mdownload_and_prepare\u001b[1;34m(self, download_config, download_mode, ignore_verifications, try_from_hf_gcs, dl_manager, base_path, use_auth_token, **download_and_prepare_kwargs)\u001b[0m\n\u001b[0;32m    577\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdownloaded_from_gcs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m                         self._download_and_prepare(\n\u001b[1;32m--> 579\u001b[1;33m                             \u001b[0mdl_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdl_manager\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_infos\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverify_infos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mdownload_and_prepare_kwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    580\u001b[0m                         )\n\u001b[0;32m    581\u001b[0m                     \u001b[1;31m# Sync info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\datasets\\builder.py\u001b[0m in \u001b[0;36m_download_and_prepare\u001b[1;34m(self, dl_manager, verify_infos, **prepare_split_kwargs)\u001b[0m\n\u001b[0;32m    654\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    655\u001b[0m                 \u001b[1;31m# Prepare split will record examples associated to the split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 656\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_prepare_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msplit_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mprepare_split_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    657\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    658\u001b[0m                 raise OSError(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\datasets\\builder.py\u001b[0m in \u001b[0;36m_prepare_split\u001b[1;34m(self, split_generator)\u001b[0m\n\u001b[0;32m    975\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    976\u001b[0m                 for key, record in utils.tqdm(\n\u001b[1;32m--> 977\u001b[1;33m                     \u001b[0mgenerator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\" examples\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msplit_info\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_examples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnot_verbose\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    978\u001b[0m                 ):\n\u001b[0;32m    979\u001b[0m                     \u001b[0mexample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode_example\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tqdm\\std.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1133\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1134\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1135\u001b[0m                 \u001b[1;31m# Update and possibly print the progressbar.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.cache\\huggingface\\modules\\datasets_modules\\datasets\\custom_dataset\\6fb6208fe296414d9c120c127158cef4dc9e6f13ac16ab3ebb16989d1004c096\\custom_dataset.py\u001b[0m in \u001b[0;36m_generate_examples\u001b[1;34m(self, filepath)\u001b[0m\n\u001b[0;32m     74\u001b[0m                 \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrespuesta\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'answer'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m                 \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrespuesta\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m                 \u001b[0mid_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrespuesta\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m                 yield id_, {\n",
      "\u001b[1;31mKeyError\u001b[0m: 'id'"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('custom_dataset.py')"
   ]
  },
  {
   "source": [
    "## Leemos los datos"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = pd.read_csv('palabras_corregidas_secundaria.csv', encoding='latin1')"
   ]
  },
  {
   "source": [
    "## Ecojemos la pregunta *Pelota de Pelos*"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                              sentence  label\n",
       "0                                que es dura o aguanta      1\n",
       "1    puede ser una medalla o una esfera color metál...      1\n",
       "2                                             una joya      1\n",
       "3                         seria muy brillosa la pelota      2\n",
       "4               da a conocer que que es uno muy fuerte      3\n",
       "..                                                 ...    ...\n",
       "465        pues tal vez la medalla esta llena de plata      1\n",
       "466  yo puse que la frase se podría referir a la lu...      3\n",
       "467                                   que es brillante      3\n",
       "468  porque ya establecimos que a todo le esta dici...      1\n",
       "469  la luna se ve como de plata o color plata y br...      3\n",
       "\n",
       "[470 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentence</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>que es dura o aguanta</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>puede ser una medalla o una esfera color metál...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>una joya</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>seria muy brillosa la pelota</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>da a conocer que que es uno muy fuerte</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>465</th>\n      <td>pues tal vez la medalla esta llena de plata</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>466</th>\n      <td>yo puse que la frase se podría referir a la lu...</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>467</th>\n      <td>que es brillante</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>468</th>\n      <td>porque ya establecimos que a todo le esta dici...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>469</th>\n      <td>la luna se ve como de plata o color plata y br...</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n<p>470 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "datos = pd.DataFrame({\n",
    "    'sentence' : csv.iloc[:,4],\n",
    "    'label' : csv.iloc[:,5]\n",
    "})\n",
    "datos"
   ]
  },
  {
   "source": [
    "## Convertimos los 3 en 1 y todo lo demás en 0, para hacer una predicción binaria"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                              sentence  label\n",
       "0                                que es dura o aguanta      0\n",
       "1    puede ser una medalla o una esfera color metál...      0\n",
       "2                                             una joya      0\n",
       "3                         seria muy brillosa la pelota      0\n",
       "4               da a conocer que que es uno muy fuerte      1\n",
       "..                                                 ...    ...\n",
       "465        pues tal vez la medalla esta llena de plata      0\n",
       "466  yo puse que la frase se podría referir a la lu...      1\n",
       "467                                   que es brillante      1\n",
       "468  porque ya establecimos que a todo le esta dici...      0\n",
       "469  la luna se ve como de plata o color plata y br...      1\n",
       "\n",
       "[470 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentence</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>que es dura o aguanta</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>puede ser una medalla o una esfera color metál...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>una joya</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>seria muy brillosa la pelota</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>da a conocer que que es uno muy fuerte</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>465</th>\n      <td>pues tal vez la medalla esta llena de plata</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>466</th>\n      <td>yo puse que la frase se podría referir a la lu...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>467</th>\n      <td>que es brillante</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>468</th>\n      <td>porque ya establecimos que a todo le esta dici...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>469</th>\n      <td>la luna se ve como de plata o color plata y br...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>470 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "datos['label'] = [1 if i == 3 else 0 for i in datos['label'].tolist()]\n",
    "datos"
   ]
  },
  {
   "source": [
    "## Importamos el tokenizer y el modelo"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at datificate/gpt2-small-spanish were not used when initializing GPT2ForSequenceClassification: ['lm_head.weight']\n",
      "- This IS expected if you are initializing GPT2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing GPT2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at datificate/gpt2-small-spanish and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "num_labels = 2\n",
    "model_checkpoint = 'datificate/gpt2-small-spanish'\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_checkpoint)\n",
    "model = GPT2ForSequenceClassification.from_pretrained(model_checkpoint, num_labels=num_labels)\n"
   ]
  },
  {
   "source": [
    "#### TrainingArguments es una clase para los argumentos del entrenamiento"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\mv502\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\cuda\\__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  ..\\c10\\cuda\\CUDAFunctions.cpp:100.)\n  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "args = TrainingArguments(\n",
    "    'prueba-gpt2',\n",
    "    evaluation_strategy='epoch',\n",
    "    learning_rate = 2e-5,\n",
    "    # per_device_train_batch_size= ------------- opcional\n",
    "    # per_device_eval_batch_size = ------------ opcional\n",
    "    num_train_epochs = 5,\n",
    "    weight_decay = 0.01,\n",
    "    load_best_model_at_end = True,\n",
    "    # metric_for_best_model = \n",
    ")"
   ]
  },
  {
   "source": [
    "## Separamos las oraciones y las labels"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = datos['sentence'].tolist()\n",
    "labels = datos['label'].tolist()"
   ]
  },
  {
   "source": [
    "## Creamos un Training y Test Set"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = []\n",
    "porcentaje_entrenamiento = 0.75\n",
    "s = sentences.copy()\n",
    "l = labels.copy()\n",
    "for i in range(int(len(l)*porcentaje_entrenamiento)):\n",
    "    n = randint(0, len(l) -1)\n",
    "    training.append({'sentence': s.pop(n), 'label': l.pop(n)})\n",
    "test = [{'sentence': s[i], 'labels': l[i]} for i in range(len(s))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "352\n118\n470\n"
     ]
    }
   ],
   "source": [
    "print(len(training))\n",
    "print(len(test))\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleAttributeError",
     "evalue": "'GPT2ForSequenceClassification' object has no attribute 'model_parallel'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleAttributeError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-102-3e88441445ca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mtrain_dataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0meval_dataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mtokenizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m )\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers-4.2.2-py3.8.egg\\transformers\\trainer.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, compute_metrics, callbacks, optimizers)\u001b[0m\n\u001b[0;32m    271\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_init\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_init\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 273\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"is_parallelizable\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_parallelizable\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_parallel\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    274\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_model_parallel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    777\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m         raise ModuleAttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[1;32m--> 779\u001b[1;33m             type(self).__name__, name))\n\u001b[0m\u001b[0;32m    780\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Module'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleAttributeError\u001b[0m: 'GPT2ForSequenceClassification' object has no attribute 'model_parallel'"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=training,\n",
    "    eval_dataset=test,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}